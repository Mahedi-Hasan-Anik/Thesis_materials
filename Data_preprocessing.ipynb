{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ai41UOb31j3Oj2IeThwK3T_zHZ0Ut7Eo",
      "authorship_tag": "ABX9TyNEHdQkFK9txqK841Di8sKI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mahedi-Hasan-Anik/Thesis_materials/blob/main/Data_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyedflib\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyedflib\n",
        "\n",
        "def process_edf_files(edf_files, label):\n",
        "\n",
        "    combined_data = []\n",
        "\n",
        "    for edf_file in edf_files:\n",
        "        try:\n",
        "            edf = pyedflib.EdfReader(edf_file)\n",
        "            n_signals = edf.signals_in_file\n",
        "\n",
        "            if n_signals != 19:\n",
        "                print(f\"Skipping {edf_file}: Expected 19 channels, found {n_signals}\")\n",
        "                continue\n",
        "\n",
        "            data = []\n",
        "            for i in range(n_signals):\n",
        "                signal = edf.readSignal(i)\n",
        "                data.append(signal)\n",
        "\n",
        "            data = np.array(data).T\n",
        "\n",
        "            data_with_label = np.c_[data, np.full((data.shape[0], 1), label)]\n",
        "\n",
        "\n",
        "            combined_data.append(data_with_label)\n",
        "\n",
        "            edf._close()\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {edf_file}: {e}\")\n",
        "\n",
        "\n",
        "    if combined_data:\n",
        "        combined_data = np.vstack(combined_data)\n",
        "        columns = [f\"Channel_{i+1}\" for i in range(19)] + [\"Label\"]\n",
        "        return pd.DataFrame(combined_data, columns=columns)\n",
        "    else:\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def combine_edf_datasets(healthy_dir, sick_dir, output_csv_path):\n",
        "\n",
        "    healthy_files = [os.path.join(healthy_dir, f) for f in os.listdir(healthy_dir) if f.endswith(\".edf\")]\n",
        "    sick_files = [os.path.join(sick_dir, f) for f in os.listdir(sick_dir) if f.endswith(\".edf\")]\n",
        "\n",
        "\n",
        "    print(\"Processing healthy files...\")\n",
        "    healthy_data = process_edf_files(healthy_files, label=0)\n",
        "\n",
        "    print(\"Processing sick files...\")\n",
        "    sick_data = process_edf_files(sick_files, label=1)\n",
        "\n",
        "\n",
        "    combined_data = pd.concat([healthy_data, sick_data], ignore_index=True)\n",
        "\n",
        "\n",
        "    combined_data.to_csv(output_csv_path, index=False)\n",
        "    print(f\"Combined dataset saved to {output_csv_path}\")\n",
        "\n",
        "\n",
        "healthy_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataverse/healthy\"\n",
        "sick_dir = \"/content/drive/MyDrive/Colab_Notebooks/dataverse/sick\"\n",
        "output_csv_path = \"/content/drive/MyDrive/Colab_Notebooks/dataverse/dataset.csv\"\n",
        "\n",
        "combine_edf_datasets(healthy_dir, sick_dir, output_csv_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXwSD0clEDLx",
        "outputId": "3f839345-50bb-42d8-8ffb-0555571ec8e2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyedflib\n",
            "  Downloading pyEDFlib-0.1.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pyedflib) (1.26.4)\n",
            "Downloading pyEDFlib-0.1.38-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyedflib\n",
            "Successfully installed pyedflib-0.1.38\n",
            "Processing healthy files...\n",
            "Processing sick files...\n",
            "Combined dataset saved to /content/drive/MyDrive/Colab_Notebooks/dataverse/dataset.csv\n"
          ]
        }
      ]
    }
  ]
}